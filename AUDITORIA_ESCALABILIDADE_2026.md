# üîç AUDITORIA DE ESCALABILIDADE - VELLARYS
**Data:** 20/01/2026  
**Analista:** Antigravity AI  
**Objetivo:** Preparar sistema para escalar de 3 ‚Üí 6 clientes  
**Vers√£o Atual:** Em Produ√ß√£o (Railway)

---

## üìä RESUMO EXECUTIVO

O **Vellarys** est√° bem estruturado para produ√ß√£o com 3 clientes. Por√©m, para **escalar com seguran√ßa para 6+ clientes**, existem **gaps cr√≠ticos** que precisam ser resolvidos ANTES da expans√£o.

### Grade de Prontid√£o para Escalabilidade

| √Årea | Status | Nota | A√ß√£o Necess√°ria |
|------|--------|------|-----------------|
| **Arquitetura** | ‚úÖ S√≥lida | 9/10 | Mant√©m |
| **Banco de Dados** | ‚ö†Ô∏è Aten√ß√£o | 7/10 | Pool + √çndices |
| **Cache** | üî¥ Cr√≠tico | 3/10 | Implementar Redis |
| **Rate Limiting** | ‚ö†Ô∏è Em Mem√≥ria | 5/10 | Migrar para Redis |
| **Testes** | üî¥ Cr√≠tico | 2/10 | Criar suite b√°sica |
| **Monitoramento** | ‚ö†Ô∏è Parcial | 6/10 | Melhorar alertas |
| **CI/CD** | ‚úÖ OK | 8/10 | Adicionar testes |
| **Seguran√ßa** | ‚úÖ Boa | 8/10 | Pequenos ajustes |
| **Documenta√ß√£o** | ‚ö†Ô∏è Parcial | 5/10 | Documentar runbook |

**Recomenda√ß√£o:** ‚ùå **N√ÉO ESCALAR** antes de resolver os itens cr√≠ticos marcados em üî¥

---

## üî¥ PROBLEMAS CR√çTICOS (RESOLVER ANTES DE ESCALAR)

### 1. **CACHE INEXISTENTE - GARGALO DE PERFORMANCE**

**Situa√ß√£o Atual:**
- Redis est√° nas depend√™ncias (`requirements.txt`) mas **N√ÉO est√° sendo usado**
- Todas as queries batem direto no PostgreSQL
- Rate limiter est√° **em mem√≥ria** (n√£o funciona com m√∫ltiplas inst√¢ncias)

**Impacto com 6 Clientes:**
- Cada request de settings/tenant = 1 query ao DB
- Com 100 mensagens/hora √ó 6 tenants = 600+ queries/hora s√≥ para settings
- Custo aumenta, lat√™ncia cresce, DB sobrecarregado

**C√≥digo Atual (message_rate_limiter.py):**
```python
# ARMAZENAMENTO EM MEM√ìRIA (para produ√ß√£o, usar Redis)
class InMemoryRateLimiter:
    """Rate limiter em mem√≥ria.
    Para produ√ß√£o com m√∫ltiplas inst√¢ncias, substituir por Redis.
    """
```

**Solu√ß√£o Necess√°ria:**
```python
# backend/src/infrastructure/services/redis_service.py (NOVO)
from redis.asyncio import Redis
from src.config import get_settings

settings = get_settings()

# Singleton Redis
_redis_client: Redis | None = None

async def get_redis() -> Redis:
    global _redis_client
    if _redis_client is None:
        _redis_client = Redis.from_url(
            settings.redis_url,
            decode_responses=True
        )
    return _redis_client

async def cache_get(key: str) -> str | None:
    redis = await get_redis()
    return await redis.get(key)

async def cache_set(key: str, value: str, ttl: int = 300):
    redis = await get_redis()
    await redis.set(key, value, ex=ttl)
```

**Estimativa:** 4-6 horas  
**Prioridade:** üî¥ CR√çTICA

---

### 2. **TESTES AUTOMATIZADOS INSUFICIENTES**

**Situa√ß√£o Atual:**
- Apenas **1 arquivo de teste** (`test_leads_api.py`) com 1 teste funcional
- Cobertura estimada: **< 2%** do c√≥digo
- Sem testes para: process_message, handoff, rate limiting, seguran√ßa

**Impacto:**
- Qualquer mudan√ßa pode quebrar funcionalidades existentes
- Bugs s√≥ aparecem em produ√ß√£o
- Medo de fazer refactoring necess√°rio
- Clientes existentes afetados por bugs de novos clientes

**Arquivos Cr√≠ticos SEM Testes:**
1. `process_message.py` (1430 linhas) - Core do sistema
2. `handoff_service.py` (553 linhas) - Distribui√ß√£o de leads
3. `security_service.py` (515 linhas) - Prote√ß√£o contra ataques
4. `ai_guard_service.py` (23886 bytes) - Seguran√ßa da IA
5. `rate_limit_service.py` (132 linhas) - Prote√ß√£o contra abuso

**Solu√ß√£o - Testes M√≠nimos Necess√°rios:**

```python
# backend/tests/test_process_message.py (NOVO)
import pytest
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_message_blocked_for_rate_limit():
    """Teste cr√≠tico: mensagens s√£o bloqueadas ap√≥s exceder limite"""
    pass

@pytest.mark.asyncio
async def test_lead_qualification_hot():
    """Teste cr√≠tico: lead marcado como hot quando tem sinais de compra"""
    pass

@pytest.mark.asyncio
async def test_handoff_triggered_on_hot_lead():
    """Teste cr√≠tico: handoff acontece automaticamente para lead hot"""
    pass

@pytest.mark.asyncio
async def test_security_blocks_prompt_injection():
    """Teste cr√≠tico: tentativas de prompt injection s√£o bloqueadas"""
    pass

@pytest.mark.asyncio
async def test_tenant_isolation():
    """Teste cr√≠tico: tenant A n√£o v√™ dados do tenant B"""
    pass
```

**Estimativa:** 16-24 horas (para 60% de cobertura cr√≠tica)  
**Prioridade:** üî¥ CR√çTICA

---

### 3. **POOL DE CONEX√ïES SUBDIMENSIONADO**

**Situa√ß√£o Atual (connection.py):**
```python
engine = create_async_engine(
    database_url,
    echo=settings.debug,
    pool_pre_ping=True,
    pool_size=10,        # ‚ö†Ô∏è Fixo
    max_overflow=20,     # ‚ö†Ô∏è Fixo
)
```

**C√°lculo para 6 Clientes:**
- M√©dia: 50 mensagens/dia/tenant √ó 6 = 300 mensagens/dia
- Pico: at√© 20 mensagens simult√¢neas
- Cada mensagem: ~3 queries (lead, messages, tenant)
- Pool atual: 10 + 20 = 30 conex√µes m√°ximas

**PROBLEMA:** Em picos, pool pode esgotar ‚Üí timeout ‚Üí mensagens perdidas

**Solu√ß√£o:**
```python
# Ajustar para ambiente din√¢mico
pool_size = int(os.getenv("DB_POOL_SIZE", "15"))
max_overflow = int(os.getenv("DB_MAX_OVERFLOW", "30"))

engine = create_async_engine(
    database_url,
    echo=settings.debug,
    pool_pre_ping=True,
    pool_size=pool_size,
    max_overflow=max_overflow,
    pool_recycle=3600,  # Recicla conex√µes velhas
    pool_timeout=30,     # Timeout mais generoso
)
```

**Estimativa:** 2 horas  
**Prioridade:** üî¥ CR√çTICA

---

## ‚ö†Ô∏è PROBLEMAS IMPORTANTES (RESOLVER EM PARALELO)

### 4. **√çNDICES DE BANCO FALTANDO PARA ESCALABILIDADE**

**√çndices Existentes (BOM):**
- `ix_leads_tenant_created` - leads por tenant/data
- `ix_leads_tenant_status` - leads por status
- `ix_leads_tenant_qual` - leads por qualifica√ß√£o
- `ix_messages_lead_created` - mensagens por lead/data

**√çndices Faltando (NECESS√ÅRIOS):**
```sql
-- Para busca por telefone (muito usado em webhooks)
CREATE INDEX ix_leads_phone ON leads(phone) WHERE phone IS NOT NULL;

-- Para reengajamento (scheduler)
CREATE INDEX ix_leads_reengagement ON leads(tenant_id, reengagement_status, last_activity_at);

-- Para audit logs (compliance)
CREATE INDEX ix_audit_logs_tenant_date ON audit_logs(tenant_id, created_at DESC);

-- Para notifica√ß√µes n√£o lidas
CREATE INDEX ix_notifications_unread ON notifications(tenant_id, read) WHERE read = false;
```

**Estimativa:** 2 horas  
**Prioridade:** ‚ö†Ô∏è IMPORTANTE

---

### 5. **AUDIT LOG N√ÉO EST√Å SENDO USADO CONSISTENTEMENTE**

**Situa√ß√£o Atual:**
- `audit_service.py` existe e √© bem implementado
- Mas **@audit_log decorator n√£o existe** 
- N√£o h√° chamadas consistentes ao log de auditoria nas rotas cr√≠ticas

**Rotas SEM Auditoria (Exemplo - Riscos para LGPD):**
- DELETE `/leads/{id}` - Exclus√£o de dados
- PUT `/settings` - Mudan√ßas de configura√ß√£o
- POST `/tenants` - Cria√ß√£o de novos clientes
- DELETE `/users/{id}` - Exclus√£o de usu√°rios

**Solu√ß√£o - Criar Decorator:**
```python
# backend/src/api/decorators.py (NOVO)
from functools import wraps
from src.infrastructure.services.audit_service import log_audit, AuditAction, AuditSeverity

def audit_log(action: AuditAction, severity: AuditSeverity = AuditSeverity.INFO):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            result = await func(*args, **kwargs)
            # Extrair db, user, tenant do request
            await log_audit(
                db=kwargs.get('db'),
                action=action,
                severity=severity,
                user_id=kwargs.get('current_user', {}).get('id'),
                tenant_id=kwargs.get('current_user', {}).get('tenant_id'),
            )
            return result
        return wrapper
    return decorator
```

**Estimativa:** 4 horas  
**Prioridade:** ‚ö†Ô∏è IMPORTANTE (LGPD)

---

### 6. **FALTA MONITORAMENTO DE M√âTRICAS DE NEG√ìCIO**

**Situa√ß√£o Atual:**
- Sentry configurado para erros ‚úÖ
- Health check b√°sico ‚úÖ
- **Mas faltam m√©tricas de neg√≥cio:**
  - Taxa de convers√£o por tenant
  - Tempo m√©dio de resposta da IA
  - Leads ignorados (sem resposta)
  - Falhas de webhook por provedor

**Solu√ß√£o - Endpoint de M√©tricas Prometheus:**
```python
# backend/src/api/routes/prometheus_metrics.py (NOVO)
from prometheus_client import Counter, Histogram, generate_latest

# M√©tricas
leads_created = Counter('velaris_leads_created_total', 'Total leads criados', ['tenant', 'source'])
messages_processed = Counter('velaris_messages_processed_total', 'Mensagens processadas', ['tenant', 'status'])
ai_response_time = Histogram('velaris_ai_response_seconds', 'Tempo de resposta da IA', ['tenant'])
handoff_completed = Counter('velaris_handoffs_total', 'Handoffs realizados', ['tenant', 'reason'])

@router.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

**Estimativa:** 6 horas  
**Prioridade:** ‚ö†Ô∏è IMPORTANTE

---

## üü° MELHORIAS RECOMENDADAS (AP√ìS RESOLVER CR√çTICOS)

### 7. **DOCUMENTA√á√ÉO DE RUNBOOK**

**Falta:**
- Procedimento de deploy
- Como investigar problemas
- Como adicionar novo tenant
- Limites e quotas por plano
- Contatos de escalonamento

**Criar:** `RUNBOOK.md` com procedimentos operacionais

**Estimativa:** 4 horas

---

### 8. **TIMEOUT E CIRCUIT BREAKER PARA OPENAI**

**Situa√ß√£o Atual:**
```python
# process_message.py
async def chat_completion_com_retry(
    messages: list,
    temperature: float,
    max_tokens: int,
    max_retries: int = settings.openai_max_retries,  # 2
    timeout: float = settings.openai_timeout_seconds, # 30s
):
```

**Problema:** Se OpenAI ficar lento/down, TODAS as mensagens travam

**Solu√ß√£o - Circuit Breaker:**
```python
import time

class CircuitBreaker:
    def __init__(self, failure_threshold=5, recovery_time=60):
        self.failures = 0
        self.threshold = failure_threshold
        self.recovery_time = recovery_time
        self.last_failure = 0
        self.state = "closed"  # closed, open, half-open
    
    def can_execute(self) -> bool:
        if self.state == "closed":
            return True
        if self.state == "open":
            if time.time() - self.last_failure > self.recovery_time:
                self.state = "half-open"
                return True
            return False
        return True  # half-open
    
    def record_failure(self):
        self.failures += 1
        self.last_failure = time.time()
        if self.failures >= self.threshold:
            self.state = "open"
    
    def record_success(self):
        self.failures = 0
        self.state = "closed"
```

**Estimativa:** 4 horas

---

### 9. **WEBSOCKETS PARA REAL-TIME**

**Situa√ß√£o Atual:**
- Frontend usa polling a cada 30s
- Ineficiente para m√∫ltiplos tenants

**Impacto com 6 Clientes:**
- 6 tenants √ó 3 usu√°rios/tenant √ó 1 poll/30s = 36 requests/minuto s√≥ de polling
- Lat√™ncia de at√© 30s para ver novo lead

**Solu√ß√£o Recomendada:**
- Implementar WebSocket para notifica√ß√µes em tempo real
- Estimativa: 8 horas

---

## üõ†Ô∏è PLANO DE A√á√ÉO PRIORIZADO

### **FASE 1: Pr√©-Requisitos para Escalar (OBRIGAT√ìRIO)**
**Prazo: 1 semana**

| # | Task | Horas | Respons√°vel |
|---|------|-------|-------------|
| 1 | Implementar Redis Cache | 6h | Dev Backend |
| 2 | Migrar Rate Limiter para Redis | 4h | Dev Backend |
| 3 | Aumentar Pool de Conex√µes | 2h | Dev Backend |
| 4 | Criar √çndices no Banco | 2h | Dev Backend |
| 5 | Testes Cr√≠ticos (5 testes) | 8h | Dev Backend |

**Total: ~22 horas**

---

### **FASE 2: Estabilidade (RECOMENDADO)**
**Prazo: 2 semanas**

| # | Task | Horas | Respons√°vel |
|---|------|-------|-------------|
| 6 | Completar Suite de Testes | 16h | Dev Backend |
| 7 | Decorator @audit_log | 4h | Dev Backend |
| 8 | M√©tricas Prometheus | 6h | Dev Backend |
| 9 | Runbook Operacional | 4h | DevOps |
| 10 | Circuit Breaker OpenAI | 4h | Dev Backend |

**Total: ~34 horas**

---

### **FASE 3: Excel√™ncia (NICE TO HAVE)**
**Prazo: 1 m√™s**

| # | Task | Horas | Respons√°vel |
|---|------|-------|-------------|
| 11 | WebSockets Real-Time | 8h | Dev Full |
| 12 | Dashboard Analytics Avan√ßado | 12h | Dev Frontend |
| 13 | A/B Testing de Prompts | 8h | Dev Backend |
| 14 | Integra√ß√£o CRMs Externos | 12h | Dev Backend |

**Total: ~40 horas**

---

## üìã CHECKLIST DE DEPLOY PARA 6 CLIENTES

### Antes de Adicionar Novos Clientes:
- [ ] Redis configurado no Railway
- [ ] Rate limiter usando Redis
- [ ] Pool de conex√µes ajustado (15/30)
- [ ] √çndices de banco criados
- [ ] 5 testes cr√≠ticos passando
- [ ] Sentry alertas configurados
- [ ] Health check respondendo < 500ms
- [ ] Backup de banco funcionando
- [ ] Runbook documentado

### Para Cada Novo Tenant:
- [ ] Criar tenant no sistema
- [ ] Configurar API WhatsApp (Z-API/360Dialog)
- [ ] Testar webhook de entrada
- [ ] Testar webhook de sa√≠da
- [ ] Configurar prompt personalizado
- [ ] Adicionar usu√°rios do cliente
- [ ] Verificar rate limits adequados
- [ ] Monitorar primeira semana

---

## üí∞ AN√ÅLISE DE CUSTO-BENEF√çCIO

### Cen√°rio SEM as Melhorias:
- **Risco de downtime:** Alto (sem testes, sem cache)
- **Custo de incidente:** R$ 5.000-10.000 (perda de leads + imagem)
- **Probabilidade de incidente:** 60% nos primeiros 30 dias

### Cen√°rio COM as Melhorias:
- **Investimento:** ~56h de desenvolvimento (~R$ 8.400 @ R$150/h)
- **Risco de downtime:** Baixo
- **Probabilidade de incidente:** < 10%

**ROI:** Investir nas melhorias √© **5x mais barato** que lidar com incidentes

---

## üéØ CONCLUS√ÉO

O **Vellarys** tem uma arquitetura s√≥lida, mas precsa de **ajustes de infraestrutura** antes de escalar. Os gaps identificados s√£o comuns em sistemas que crescem r√°pido - o importante √© resolv√™-los ANTES de dobrar a base de clientes.

**Recomenda√ß√£o Final:**
1. ‚úÖ **FASE 1 √© OBRIGAT√ìRIA** antes de adicionar o 4¬∫ cliente
2. ‚ö†Ô∏è **FASE 2 deve ser come√ßada em paralelo**
3. üü° **FASE 3 pode aguardar estabilidade p√≥s-escala**

---

*Auditoria realizada por Antigravity AI em 20/01/2026*
