"""
SERVIÃ‡O OPENAI - VERSÃƒO OTIMIZADA
===================================

IntegraÃ§Ã£o com a API da OpenAI.
MELHORIAS:
- Resumos curtos e objetivos
- QualificaÃ§Ã£o precisa de leads
- Prompts otimizados
- ValidaÃ§Ã£o robusta
- Temperature ajustado
"""

import json
import random
import logging
from datetime import datetime, timedelta
from openai import AsyncOpenAI
from src.config import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)

# Cliente OpenAI (singleton)
client = AsyncOpenAI(api_key=settings.openai_api_key)


# ============================================
# VARIAÃ‡Ã•ES DE SAUDAÃ‡Ã•ES E RESPOSTAS
# ============================================

GREETING_VARIATIONS = {
    "formal": [
        "OlÃ¡! Como posso ajudÃ¡-lo hoje?",
        "OlÃ¡! Em que posso ser Ãºtil?",
        "Bom dia! Como posso auxiliÃ¡-lo?",
        "OlÃ¡! Estou Ã  disposiÃ§Ã£o para ajudar.",
    ],
    "cordial": [
        "Oi! ğŸ˜Š Como posso te ajudar?",
        "OlÃ¡! Tudo bem? Em que posso ajudar?",
        "Oi! Que bom falar com vocÃª! Como posso ajudar?",
        "OlÃ¡! ğŸ‘‹ Estou aqui pra te ajudar!",
    ],
    "informal": [
        "E aÃ­! ğŸ‘‹ Como posso te ajudar?",
        "Oi! Tudo certo? Bora lÃ¡, como posso ajudar?",
        "Fala! ğŸ˜„ O que vocÃª precisa?",
        "Oi oi! Como posso te ajudar hoje?",
    ],
}


def get_random_greeting(tone: str = "cordial") -> str:
    """Retorna uma saudaÃ§Ã£o aleatÃ³ria baseada no tom."""
    greetings = GREETING_VARIATIONS.get(tone, GREETING_VARIATIONS["cordial"])
    return random.choice(greetings)



# ============================================
# FUNÃ‡Ã•ES PRINCIPAIS
# ============================================

async def chat_completion(
    messages: list[dict],
    model: str = None,
    temperature: float = 0.65,
    max_tokens: int = 350,
) -> dict:
    """Envia mensagens para OpenAI e retorna resposta."""
    try:
        response = await client.chat.completions.create(
            model=model or settings.openai_model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            # SEM tools, SEM enable_web_search
        )

        return {
            "content": response.choices[0].message.content,
            "tokens_used": response.usage.total_tokens if response.usage else 0
        }
    except Exception as e:
        logger.error(f"Erro na chamada OpenAI: {e}")
        return {
            "content": "Desculpe, tive um problema tÃ©cnico. Pode repetir?",
            "tokens_used": 0
        }


def validate_ai_response(
    response: str,
    lead_name: str = None,
    lead_phone: str = None,
    history: list[dict] = None,
) -> tuple[str, bool]:
    """
    Valida resposta da IA - VERSÃƒO LEVE (sem substituiÃ§Ãµes agressivas).
    
    Remove apenas:
    - Vazamentos de dados sensÃ­veis
    - Respostas vazias/quebradas
    
    Retorna: (resposta_validada, foi_corrigida)
    """
    import re
    
    original_response = response
    was_corrected = False
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. REMOVE VAZAMENTO DE TELEFONE/EMAIL
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Remove telefones expostos (exceto se for o prÃ³prio lead)
    phone_pattern = r'\b\d{10,11}\b|\b\(\d{2}\)\s*\d{4,5}-?\d{4}\b'
    phones_found = re.findall(phone_pattern, response)
    
    for phone in phones_found:
        clean_phone = re.sub(r'\D', '', phone)
        # Se nÃ£o for o telefone do lead, remove
        if lead_phone:
            lead_clean = re.sub(r'\D', '', lead_phone)
            if clean_phone != lead_clean:
                response = response.replace(phone, "[REMOVIDO]")
                was_corrected = True
                logger.warning(f"âš ï¸ Telefone vazado removido: {phone}")
    
    # Remove emails expostos
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    if re.search(email_pattern, response):
        response = re.sub(email_pattern, "[EMAIL]", response)
        was_corrected = True
        logger.warning(f"âš ï¸ Email vazado removido")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. LIMPA RESPOSTAS VAZIAS/QUEBRADAS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    response = response.strip()
    
    # Remove artefatos comuns
    response = re.sub(r'^(Resposta:|IA:|Assistente:)\s*', '', response, flags=re.IGNORECASE)
    response = response.strip()
    
    # Se ficou vazio apÃ³s limpeza
    if not response or len(response) < 3:
        response = "Desculpe, pode repetir? NÃ£o entendi bem."
        was_corrected = True
        logger.warning(f"âš ï¸ Resposta vazia corrigida")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. LOG (se corrigiu)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    if was_corrected:
        logger.info(f"âœ‚ï¸ Resposta validada: '{original_response[:50]}...' â†’ '{response[:50]}...'")
    
    return response, was_corrected

async def detect_sentiment(message: str) -> dict:
    """
    Detecta o sentimento/humor do lead na mensagem.
    AnÃ¡lise rÃ¡pida por palavras-chave (sem chamar API).
    """
    
    message_lower = message.lower()
    
    # Sinais de frustraÃ§Ã£o/irritaÃ§Ã£o
    frustrated_signals = [
        "demora", "lento", "ninguÃ©m responde", "pÃ©ssimo", "horrÃ­vel",
        "nÃ£o funciona", "problema", "reclamaÃ§Ã£o", "absurdo", "vergonha",
        "desisto", "cancelar", "nunca mais", "pior", "raiva", "irritado",
        "cansado de", "toda vez", "sempre isso", "!!", "???",
    ]
    
    # Sinais de pressa/urgÃªncia
    urgent_signals = [
        "urgente", "rÃ¡pido", "agora", "hoje", "preciso logo",
        "nÃ£o posso esperar", "emergÃªncia", "prazo", "deadline",
    ]
    
    # Sinais positivos/animaÃ§Ã£o
    positive_signals = [
        "obrigado", "obrigada", "perfeito", "Ã³timo", "excelente",
        "maravilha", "adorei", "amei", "show", "top", "ğŸ˜Š", "ğŸ˜„",
        "ğŸ‘", "ğŸ™", "â¤ï¸", "muito bom", "gostei",
    ]
    
    # Sinais de interesse forte
    excited_signals = [
        "quero", "preciso", "vamos fechar", "quando comeÃ§a",
        "como faÃ§o", "me inscreve", "reserva", "!!",
    ]
    
    # Pontua cada categoria
    frustrated_score = sum(1 for s in frustrated_signals if s in message_lower)
    urgent_score = sum(1 for s in urgent_signals if s in message_lower)
    positive_score = sum(1 for s in positive_signals if s in message_lower)
    excited_score = sum(1 for s in excited_signals if s in message_lower)
    
    # Determina sentimento predominante
    if frustrated_score >= 2:
        return {
            "sentiment": "frustrated",
            "confidence": min(0.9, 0.5 + frustrated_score * 0.1),
            "tone_adjustment": "Seja empÃ¡tico, resolva rapidamente. Evite frases genÃ©ricas.",
            "detected_signals": "frustraÃ§Ã£o"
        }
    elif urgent_score >= 1:
        return {
            "sentiment": "urgent",
            "confidence": min(0.9, 0.6 + urgent_score * 0.1),
            "tone_adjustment": "Seja direto e objetivo. Priorize resolver a urgÃªncia.",
            "detected_signals": "urgÃªncia"
        }
    elif excited_score >= 1 and positive_score >= 1:
        return {
            "sentiment": "excited",
            "confidence": 0.8,
            "tone_adjustment": "Mantenha a energia! Facilite o fechamento.",
            "detected_signals": "animaÃ§Ã£o"
        }
    elif positive_score >= 1:
        return {
            "sentiment": "positive",
            "confidence": min(0.9, 0.6 + positive_score * 0.1),
            "tone_adjustment": "Continue positivo. Bom momento para qualificar.",
            "detected_signals": "satisfaÃ§Ã£o"
        }
    else:
        return {
            "sentiment": "neutral",
            "confidence": 0.5,
            "tone_adjustment": None,
            "detected_signals": None
        }


async def extract_lead_data(
    conversation: list[dict],
    required_fields: list[str],
    optional_fields: list[str],
) -> dict:
    """
    Extrai dados estruturados do lead a partir da conversa.
    OTIMIZADO: Prompt mais curto e direto.
    """

    all_fields = required_fields + optional_fields

    extraction_prompt = f"""Extraia informaÃ§Ãµes do cliente desta conversa.

CAMPOS: {json.dumps(all_fields, ensure_ascii=False)}

EXTRAS (se mencionado):
- family_situation, work_info, budget_range, urgency_level
- preferences, pain_points, objections, buying_signals

CONVERSA (Ãºltimas 10 mensagens):
{json.dumps(conversation[-10:], ensure_ascii=False)}

Retorne APENAS JSON vÃ¡lido. Use null se nÃ£o mencionado.

JSON:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": extraction_prompt}],
            temperature=0.1,
            max_tokens=600,
        )

        content = response.choices[0].message.content.strip()
        
        # Remove markdown se houver
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
        
        return json.loads(content)
    except (json.JSONDecodeError, IndexError, Exception) as e:
        logger.error(f"Erro ao extrair dados do lead: {e}")
        return {}


async def qualify_lead(
    conversation: list[dict],
    extracted_data: dict,
    qualification_rules: dict,
) -> dict:
    """
    Qualifica o lead como hot/warm/cold.
    CORRIGIDO: NÃ£o marca leads interessados como "frio".
    """

    qualification_prompt = f"""Qualifique este lead como HOT, WARM ou COLD.

CRITÃ‰RIOS:
ğŸ”¥ HOT (pronto para comprar):
- Perguntou sobre pagamento/preÃ§o
- Perguntou disponibilidade/quando pode comeÃ§ar
- Tem prazo definido
- Demonstra urgÃªncia clara

ğŸŸ¡ WARM (interessado):
- Fez vÃ¡rias perguntas
- EstÃ¡ comparando opÃ§Ãµes
- Tem interesse claro mas sem urgÃªncia
- Respondeu perguntas de qualificaÃ§Ã£o

ğŸ”µ COLD (sÃ³ pesquisando):
- Poucas mensagens
- Respostas curtas/vagas
- "SÃ³ olhando"/"Depois eu vejo"

DADOS:
{json.dumps(extracted_data, ensure_ascii=False)}

CONVERSA (Ãºltimas 8):
{json.dumps(conversation[-8:], ensure_ascii=False)}

Retorne APENAS JSON:
{{
  "qualification": "hot|warm|cold",
  "confidence": 0.0-1.0,
  "reason": "motivo em 1 linha",
  "buying_signals_found": ["sinal1", "sinal2"],
  "recommended_action": "aÃ§Ã£o para o vendedor"
}}

JSON:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": qualification_prompt}],
            temperature=0.15,  # Mais determinÃ­stico
            max_tokens=300,
        )

        content = response.choices[0].message.content.strip()
        
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
        
        result = json.loads(content)
        
        # ValidaÃ§Ã£o: Se tem buying_signals, nÃ£o pode ser cold
        if result.get("buying_signals_found") and result.get("qualification") == "cold":
            result["qualification"] = "warm"
            logger.warning("Corrigido: Lead com sinais de compra marcado como cold")
        
        return result
        
    except (json.JSONDecodeError, IndexError, Exception) as e:
        logger.error(f"Erro ao qualificar lead: {e}")
        return {
            "qualification": "warm",
            "confidence": 0.5,
            "reason": "Erro na qualificaÃ§Ã£o, classificado como warm por seguranÃ§a",
            "buying_signals_found": [],
            "recommended_action": "Continuar qualificaÃ§Ã£o"
        }


async def generate_lead_summary(
    conversation: list[dict],
    extracted_data: dict,
    qualification: dict,
) -> str:
    """
    Gera resumo CURTO e ÃšTIL para o vendedor.
    MÃ¡ximo 5 linhas, informaÃ§Ãµes acionÃ¡veis.
    """

    lead_name = extracted_data.get("name", "Cliente")
    
    # Interesse principal
    interest = "informaÃ§Ãµes"
    if extracted_data.get("preferences"):
        prefs = extracted_data["preferences"]
        if isinstance(prefs, list) and prefs:
            interest = prefs[0][:30]
        elif isinstance(prefs, str):
            interest = prefs[:30]
    
    # QualificaÃ§Ã£o
    qual = qualification.get("qualification", "cold").upper()
    
    # UrgÃªncia
    urgency = "MÃ©dia"
    if qual == "HOT":
        urgency = "Alta"
    elif qual == "COLD":
        urgency = "Baixa"
    
    # OrÃ§amento
    budget = extracted_data.get("budget_range", "NÃ£o informado")
    if isinstance(budget, str) and len(budget) > 25:
        budget = budget[:22] + "..."
    
    # PrÃ³ximo passo
    next_step = qualification.get("recommended_action", "Fazer contato")
    if len(next_step) > 35:
        next_step = next_step[:32] + "..."

    summary_prompt = f"""Crie resumo ULTRA CURTO para vendedor (5 linhas, 40 chars/linha).

DADOS:
- Cliente: {lead_name}
- Busca: {interest}
- Status: {qual}
- UrgÃªncia: {urgency}
- OrÃ§amento: {budget}

CONVERSA (Ãºltimas 3 mensagens):
{json.dumps(conversation[-3:], ensure_ascii=False)}

FORMATO (EXATAMENTE assim):
ğŸ¯ {lead_name} quer [resumo do interesse]
ğŸ“ Busca [especifique o que procura]
â° UrgÃªncia {urgency} - [motivo curto]
ğŸ’° {budget}
âœ… AÃ§Ã£o: [prÃ³ximo passo]

REGRAS:
- MÃXIMO 40 caracteres por linha
- SEM asteriscos, SEM bullets
- Emojis APENAS no inÃ­cio
- DIRETO, ACIONÃVEL

RESUMO:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": summary_prompt}],
            temperature=0.1,
            max_tokens=150,
        )

        summary = response.choices[0].message.content.strip()
        
        # Limpa formataÃ§Ã£o
        summary = summary.replace("**", "").replace("- ", "").replace("* ", "")
        
        # ForÃ§a 5 linhas
        lines = [line.strip() for line in summary.split('\n') if line.strip()]
        if len(lines) > 5:
            lines = lines[:5]
            logger.warning(f"Resumo truncado de {len(lines)} para 5 linhas")
        elif len(lines) < 5:
            # Completa com linha de aÃ§Ã£o se faltar
            while len(lines) < 5:
                lines.append(f"âœ… AÃ§Ã£o: {next_step}")
        
        # Limita tamanho de cada linha
        lines = [line[:60] if len(line) > 60 else line for line in lines]
        
        return '\n'.join(lines)
        
    except Exception as e:
        logger.error(f"Erro ao gerar resumo: {e}")
        # Fallback direto e garantido
        return f"""ğŸ¯ {lead_name} quer {interest[:20]}
ğŸ“ Interesse em {qual}
â° UrgÃªncia {urgency}
ğŸ’° {budget}
âœ… AÃ§Ã£o: {next_step[:30]}"""


async def generate_conversation_summary(conversation: list[dict]) -> str:
    """
    Gera um resumo curto da conversa (mÃ¡ximo 100 caracteres).
    Para uso em retorno do lead.
    """
    
    if len(conversation) < 2:
        return None
    
    summary_prompt = f"""Resuma em 1 frase curta (mÃ¡ximo 80 caracteres) o que o cliente queria.

CONVERSA:
{json.dumps(conversation[-6:], ensure_ascii=False)}

Formato: "Queria saber sobre [X]"
SEM saudaÃ§Ãµes, SEM formalidades.

RESUMO:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": summary_prompt}],
            temperature=0.2,
            max_tokens=50,
        )
        
        summary = response.choices[0].message.content.strip()
        
        # Garante mÃ¡ximo 100 caracteres
        if len(summary) > 100:
            summary = summary[:97] + "..."
        
        return summary
        
    except Exception as e:
        logger.error(f"Erro ao gerar resumo da conversa: {e}")
        return None


# ============================================
# HELPERS
# ============================================

def calculate_typing_delay(message_length: int) -> float:
    """
    Calcula delay de digitaÃ§Ã£o baseado no tamanho da mensagem.
    Entre 1 e 5 segundos.
    """
    words = message_length / 5
    seconds = words / 40 * 60
    
    delay = max(1.0, min(5.0, seconds))
    
    # Adiciona variaÃ§Ã£o aleatÃ³ria de Â±20%
    variation = delay * 0.2 * (random.random() * 2 - 1)
    
    return round(delay + variation, 1)