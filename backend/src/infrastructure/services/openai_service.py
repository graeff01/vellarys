"""
SERVI√áO OPENAI - VERS√ÉO OTIMIZADA
===================================

Integra√ß√£o com a API da OpenAI.
MELHORIAS:
- Resumos curtos e objetivos
- Qualifica√ß√£o precisa de leads
- Prompts otimizados
- Valida√ß√£o robusta
- Temperature ajustado
"""

import json
import random
import logging
from datetime import datetime, timedelta
from openai import AsyncOpenAI
from src.config import get_settings

settings = get_settings()
logger = logging.getLogger(__name__)

# Cliente OpenAI (singleton)
client = AsyncOpenAI(api_key=settings.openai_api_key)


# ============================================
# VARIA√á√ïES DE SAUDA√á√ïES E RESPOSTAS
# ============================================

GREETING_VARIATIONS = {
    "formal": [
        "Ol√°! Como posso ajud√°-lo hoje?",
        "Ol√°! Em que posso ser √∫til?",
        "Bom dia! Como posso auxili√°-lo?",
        "Ol√°! Estou √† disposi√ß√£o para ajudar.",
    ],
    "cordial": [
        "Oi! üòä Como posso te ajudar?",
        "Ol√°! Tudo bem? Em que posso ajudar?",
        "Oi! Que bom falar com voc√™! Como posso ajudar?",
        "Ol√°! üëã Estou aqui pra te ajudar!",
    ],
    "informal": [
        "E a√≠! üëã Como posso te ajudar?",
        "Oi! Tudo certo? Bora l√°, como posso ajudar?",
        "Fala! üòÑ O que voc√™ precisa?",
        "Oi oi! Como posso te ajudar hoje?",
    ],
}


def get_random_greeting(tone: str = "cordial") -> str:
    """Retorna uma sauda√ß√£o aleat√≥ria baseada no tom."""
    greetings = GREETING_VARIATIONS.get(tone, GREETING_VARIATIONS["cordial"])
    return random.choice(greetings)


# ============================================
# FUN√á√ïES PRINCIPAIS
# ============================================

async def chat_completion(
    messages: list[dict],
    model: str = None,
    temperature: float = 0.7,
    max_tokens: int = 500,
) -> dict:
    """Envia mensagens para OpenAI e retorna resposta."""
    try:
        response = await client.chat.completions.create(
            model=model or settings.openai_model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )

        return {
            "content": response.choices[0].message.content,
            "tokens_used": response.usage.total_tokens if response.usage else 0
        }
    except Exception as e:
        logger.error(f"Erro na chamada OpenAI: {e}")
        return {
            "content": "Desculpe, tive um problema t√©cnico. Pode repetir?",
            "tokens_used": 0
        }


async def detect_sentiment(message: str) -> dict:
    """
    Detecta o sentimento/humor do lead na mensagem.
    An√°lise r√°pida por palavras-chave (sem chamar API).
    """
    
    message_lower = message.lower()
    
    # Sinais de frustra√ß√£o/irrita√ß√£o
    frustrated_signals = [
        "demora", "lento", "ningu√©m responde", "p√©ssimo", "horr√≠vel",
        "n√£o funciona", "problema", "reclama√ß√£o", "absurdo", "vergonha",
        "desisto", "cancelar", "nunca mais", "pior", "raiva", "irritado",
        "cansado de", "toda vez", "sempre isso", "!!", "???",
    ]
    
    # Sinais de pressa/urg√™ncia
    urgent_signals = [
        "urgente", "r√°pido", "agora", "hoje", "preciso logo",
        "n√£o posso esperar", "emerg√™ncia", "prazo", "deadline",
    ]
    
    # Sinais positivos/anima√ß√£o
    positive_signals = [
        "obrigado", "obrigada", "perfeito", "√≥timo", "excelente",
        "maravilha", "adorei", "amei", "show", "top", "üòä", "üòÑ",
        "üëç", "üôè", "‚ù§Ô∏è", "muito bom", "gostei",
    ]
    
    # Sinais de interesse forte
    excited_signals = [
        "quero", "preciso", "vamos fechar", "quando come√ßa",
        "como fa√ßo", "me inscreve", "reserva", "!!",
    ]
    
    # Pontua cada categoria
    frustrated_score = sum(1 for s in frustrated_signals if s in message_lower)
    urgent_score = sum(1 for s in urgent_signals if s in message_lower)
    positive_score = sum(1 for s in positive_signals if s in message_lower)
    excited_score = sum(1 for s in excited_signals if s in message_lower)
    
    # Determina sentimento predominante
    if frustrated_score >= 2:
        return {
            "sentiment": "frustrated",
            "confidence": min(0.9, 0.5 + frustrated_score * 0.1),
            "tone_adjustment": "Seja emp√°tico, resolva rapidamente. Evite frases gen√©ricas.",
            "detected_signals": "frustra√ß√£o"
        }
    elif urgent_score >= 1:
        return {
            "sentiment": "urgent",
            "confidence": min(0.9, 0.6 + urgent_score * 0.1),
            "tone_adjustment": "Seja direto e objetivo. Priorize resolver a urg√™ncia.",
            "detected_signals": "urg√™ncia"
        }
    elif excited_score >= 1 and positive_score >= 1:
        return {
            "sentiment": "excited",
            "confidence": 0.8,
            "tone_adjustment": "Mantenha a energia! Facilite o fechamento.",
            "detected_signals": "anima√ß√£o"
        }
    elif positive_score >= 1:
        return {
            "sentiment": "positive",
            "confidence": min(0.9, 0.6 + positive_score * 0.1),
            "tone_adjustment": "Continue positivo. Bom momento para qualificar.",
            "detected_signals": "satisfa√ß√£o"
        }
    else:
        return {
            "sentiment": "neutral",
            "confidence": 0.5,
            "tone_adjustment": None,
            "detected_signals": None
        }


async def extract_lead_data(
    conversation: list[dict],
    required_fields: list[str],
    optional_fields: list[str],
) -> dict:
    """
    Extrai dados estruturados do lead a partir da conversa.
    OTIMIZADO: Prompt mais curto e direto.
    """

    all_fields = required_fields + optional_fields

    extraction_prompt = f"""Extraia informa√ß√µes do cliente desta conversa.

CAMPOS: {json.dumps(all_fields, ensure_ascii=False)}

EXTRAS (se mencionado):
- family_situation, work_info, budget_range, urgency_level
- preferences, pain_points, objections, buying_signals

CONVERSA (√∫ltimas 10 mensagens):
{json.dumps(conversation[-10:], ensure_ascii=False)}

Retorne APENAS JSON v√°lido. Use null se n√£o mencionado.

JSON:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": extraction_prompt}],
            temperature=0.1,
            max_tokens=600,
        )

        content = response.choices[0].message.content.strip()
        
        # Remove markdown se houver
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
        
        return json.loads(content)
    except (json.JSONDecodeError, IndexError, Exception) as e:
        logger.error(f"Erro ao extrair dados do lead: {e}")
        return {}


async def qualify_lead(
    conversation: list[dict],
    extracted_data: dict,
    qualification_rules: dict,
) -> dict:
    """
    Qualifica o lead como hot/warm/cold.
    CORRIGIDO: N√£o marca leads interessados como "frio".
    """

    qualification_prompt = f"""Qualifique este lead como HOT, WARM ou COLD.

CRIT√âRIOS:
üî• HOT (pronto para comprar):
- Perguntou sobre pagamento/pre√ßo
- Perguntou disponibilidade/quando pode come√ßar
- Tem prazo definido
- Demonstra urg√™ncia clara

üü° WARM (interessado):
- Fez v√°rias perguntas
- Est√° comparando op√ß√µes
- Tem interesse claro mas sem urg√™ncia
- Respondeu perguntas de qualifica√ß√£o

üîµ COLD (s√≥ pesquisando):
- Poucas mensagens
- Respostas curtas/vagas
- "S√≥ olhando"/"Depois eu vejo"

DADOS:
{json.dumps(extracted_data, ensure_ascii=False)}

CONVERSA (√∫ltimas 8):
{json.dumps(conversation[-8:], ensure_ascii=False)}

Retorne APENAS JSON:
{{
  "qualification": "hot|warm|cold",
  "confidence": 0.0-1.0,
  "reason": "motivo em 1 linha",
  "buying_signals_found": ["sinal1", "sinal2"],
  "recommended_action": "a√ß√£o para o vendedor"
}}

JSON:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": qualification_prompt}],
            temperature=0.15,  # Mais determin√≠stico
            max_tokens=300,
        )

        content = response.choices[0].message.content.strip()
        
        if content.startswith("```"):
            content = content.split("```")[1]
            if content.startswith("json"):
                content = content[4:]
        
        result = json.loads(content)
        
        # Valida√ß√£o: Se tem buying_signals, n√£o pode ser cold
        if result.get("buying_signals_found") and result.get("qualification") == "cold":
            result["qualification"] = "warm"
            logger.warning("Corrigido: Lead com sinais de compra marcado como cold")
        
        return result
        
    except (json.JSONDecodeError, IndexError, Exception) as e:
        logger.error(f"Erro ao qualificar lead: {e}")
        return {
            "qualification": "warm",
            "confidence": 0.5,
            "reason": "Erro na qualifica√ß√£o, classificado como warm por seguran√ßa",
            "buying_signals_found": [],
            "recommended_action": "Continuar qualifica√ß√£o"
        }


async def generate_lead_summary(
    conversation: list[dict],
    extracted_data: dict,
    qualification: dict,
) -> str:
    """
    Gera resumo CURTO e OBJETIVO do lead para o vendedor.
    CORRIGIDO: M√°ximo 5 linhas, sem formata√ß√£o excessiva.
    """

    # Pega nome do lead
    lead_name = extracted_data.get("name", "Cliente")
    
    # Pega interesse principal
    interest = "informa√ß√µes sobre o servi√ßo"
    if extracted_data.get("preferences"):
        prefs = extracted_data["preferences"]
        if isinstance(prefs, list) and prefs:
            interest = prefs[0]
        elif isinstance(prefs, str):
            interest = prefs
    
    # Urg√™ncia
    urgency_level = extracted_data.get("urgency_level", "n√£o informada")
    if qualification.get("qualification") == "hot":
        urgency_display = "Alta"
    elif urgency_level and urgency_level != "n√£o informada":
        urgency_display = urgency_level.capitalize()
    else:
        urgency_display = "M√©dia" if qualification.get("qualification") == "warm" else "Baixa"
    
    # Or√ßamento
    budget = extracted_data.get("budget_range", "N√£o informado")
    
    # Pr√≥ximo passo
    next_step = qualification.get("recommended_action", "Continuar qualifica√ß√£o")

    summary_prompt = f"""Crie um resumo CURTO para o vendedor (m√°ximo 5 linhas).

DADOS:
- Nome: {lead_name}
- Interesse: {interest}
- Qualifica√ß√£o: {qualification.get('qualification', 'N/A').upper()}
- Urg√™ncia: {urgency_display}
- Or√ßamento: {budget}
- A√ß√£o: {next_step}

CONVERSA (√∫ltimas 4):
{json.dumps(conversation[-4:], ensure_ascii=False)}

FORMATO OBRIGAT√ìRIO (m√°ximo 5 linhas, sem asteriscos, sem bullets):

üéØ [Nome] quer [interesse em 5 palavras]
üìç Busca: [especifica√ß√£o em 5 palavras]
‚è∞ Urg√™ncia: [Alta/M√©dia/Baixa] - [motivo em 3 palavras]
üí∞ Or√ßamento: [faixa ou "N√£o informado"]
‚úÖ A√ß√£o: [pr√≥ximo passo em 5 palavras]

REGRAS:
- M√ÅXIMO 5 LINHAS (n√£o pode passar!)
- SEM formata√ß√£o (**bold**, bullets, etc)
- Emojis APENAS no in√≠cio de cada linha
- DIRETO E OBJETIVO
- Cada linha com NO M√ÅXIMO 50 caracteres

RESUMO:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": summary_prompt}],
            temperature=0.1,  # Muito determin√≠stico
            max_tokens=150,   # Limita tamanho
        )

        summary = response.choices[0].message.content.strip()
        
        # Remove formata√ß√£o excessiva
        summary = summary.replace("**", "").replace("- ", "")
        
        # Garante m√°ximo 5 linhas
        lines = [line.strip() for line in summary.split('\n') if line.strip()]
        if len(lines) > 5:
            lines = lines[:5]
            logger.warning("Resumo tinha mais de 5 linhas, truncado")
        
        return '\n'.join(lines)
        
    except Exception as e:
        logger.error(f"Erro ao gerar resumo: {e}")
        # Fallback seguro
        return f"""üéØ {lead_name} quer {interest[:30]}
üìç Interesse demonstrado na conversa
‚è∞ Urg√™ncia: {urgency_display}
üí∞ Or√ßamento: {budget}
‚úÖ A√ß√£o: Fazer contato"""


async def generate_conversation_summary(conversation: list[dict]) -> str:
    """
    Gera um resumo curto da conversa (m√°ximo 100 caracteres).
    Para uso em retorno do lead.
    """
    
    if len(conversation) < 2:
        return None
    
    summary_prompt = f"""Resuma em 1 frase curta (m√°ximo 80 caracteres) o que o cliente queria.

CONVERSA:
{json.dumps(conversation[-6:], ensure_ascii=False)}

Formato: "Queria saber sobre [X]"
SEM sauda√ß√µes, SEM formalidades.

RESUMO:"""

    try:
        response = await client.chat.completions.create(
            model=settings.openai_model,
            messages=[{"role": "user", "content": summary_prompt}],
            temperature=0.2,
            max_tokens=50,
        )
        
        summary = response.choices[0].message.content.strip()
        
        # Garante m√°ximo 100 caracteres
        if len(summary) > 100:
            summary = summary[:97] + "..."
        
        return summary
        
    except Exception as e:
        logger.error(f"Erro ao gerar resumo da conversa: {e}")
        return None


# ============================================
# HELPERS
# ============================================

def calculate_typing_delay(message_length: int) -> float:
    """
    Calcula delay de digita√ß√£o baseado no tamanho da mensagem.
    Entre 1 e 5 segundos.
    """
    words = message_length / 5
    seconds = words / 40 * 60
    
    delay = max(1.0, min(5.0, seconds))
    
    # Adiciona varia√ß√£o aleat√≥ria de ¬±20%
    variation = delay * 0.2 * (random.random() * 2 - 1)
    
    return round(delay + variation, 1)